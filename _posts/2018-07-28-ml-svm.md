---
title:  “Spark ML - 支持向量机”
date:   2018-07-28 08:00:12 +0800
categories: machine learning
---

第一次听Andrew Ng斯坦福机器学习课程时候，到了SVM（支持向量机）就完全听懵了，数学基础比较差，看了三四遍才算大致了解了推导过程。SVM在解决小样本，非线性模型中表现出许多特有优势。


# **最优线性分类器**

SVM从一个线性可分问题开始推导的，即找到一条分割线将两类数据完美的分开，满足离分隔面最近的数据点具有最大距离。这些距离分隔平面最近的点就是支持向量（Support Vectors）。

![image01]({{site.baseurl}}/image/20180728/svm.png)

下面进行分隔距离的定义。分隔超平面（Hyper Plane）表示为

$$
w^Tx + b = 0
$$

函数间隔（Functional Margin）

$$
\begin{aligned}
&\hat{\gamma^i} = y^i(w^Tx^i + b) \\
&If \ y^i=1, want \ w^Tx^i + b \gg 0 \\
&If \ y^i=-1, want \ w^Tx^i + b \ll 0
\end{aligned}
$$

我们需要函数间隔最大化，但是参数对函数间隔的值影响很大，比如将参数值翻倍。于是定义几何间隔（Geometric Margin）

$$
\gamma^i = y^i\left ( \frac{w}{\| w \|} \centerdot x^i + \frac{b}{\| w \|} \right)
$$

目标函数

$$
\mathop{\arg\max\limits_{w,b} \min\limits_i \frac{1}{\| w \|} \centerdot y^i \centerdot (w^Tx^i+ b) }
$$

如果换一个方式描述

$$
\begin{aligned}
&\mathop{\arg\max\limits_{w,b}} \frac{\hat{\gamma}}{\| w \|} \\
&subject \ to: \\
&y^i \centerdot (w^Tx^i + b) \geq \hat{\gamma}, i = 1, 2, \cdots, m
\end{aligned}
$$

下面给一个约束条件
$$ \hat{\gamma} = \min\limits_i y^i \centerdot (w^Tx^i + b) = 1 $$，即最小函数间隔为1，最优化问题转换为：

$$
\begin{aligned}
&\mathop{\arg\max\limits_{w,b}} \frac{1}{\| w \|} = \mathop{\arg\min\limits_{w,b}} \| w \| \\
&subject \ to: \\
&y^i \centerdot (w^Tx^i + b) \geq 1, i = 1, 2, \cdots, m
\end{aligned}
$$

这是一个线性不等式约束下的二次优化问题，下面使用拉格朗日乘数法优化目标：

$$
\mathcal{L}(w,b,\alpha) = \frac{1}{2} \| w \|^2 - \sum\limits_{i=1}^m \alpha^i \centerdot (y^i(w^Tx^i + b)-1)
$$

然后定义：

$$
\Theta(w) = \max_{a^i \ge 0} \mathcal{L}(w,b,\alpha)
$$

令$$ g^i(w, b) = -y^i(w^Tx^i + b) + 1 \leq 0 $$
- 如果 $$ \alpha^i > 0 $$，根据KKT条件 $$ g^i(w, b) = 0 $$，则函数间隔等于1，对应$$ x^i $$是一个支持向量
- 如果 $$ \alpha^i = 0 $$，$$ g^i(w, b) \leq 0 $$不起约束作用，对应$$ x^i $$不是一个支持向量

在约束条件得到满足条件下，$$ \Theta(w) = \frac{1}{2} \| w \|^2 $$，即我们最初希望最小化$$ \frac{1}{2} \| w \|^2 $$等价于最小化$$ \Theta(w) $$。（因为当某个约束条件不满足时，$$ \Theta(w) = \infty $$）

$$
\min_{w,b} \Theta(w) = \min_{w,b} \max_{a^i \ge 0} \mathcal{L}(w,b,\alpha) = p^*
$$

交换一下min和max的位置

$$
\max_{a^i \ge 0} \min_{w,b} \mathcal{L}(w,b,\alpha) = d^*
$$

原问题转化为了一个对偶问题，且$$ d* \le p* $$ (之前老是记不住不等号方向，后来有人教了个记忆方法叫“先下手为强”，先取max的数大，即$$ \max\min \le \min\max $$)。某一课程中提到，无论原问题是否是凸函数，对偶问题都是一个凸优化问题，但不知道证明。对偶问题得到了原问题的下界，当满足KKT条件时，等号成立。

现在将$$ L $$看成$$ w, b $$的函数，目标是$$ \min\limits_{w,b} \mathcal{L}(w,b,\alpha) $$，通过梯度求得极小值必要条件。

$$
\begin{aligned}
&\frac{\partial \mathcal{L}}{\partial w} = 0 \Rightarrow w = \sum\limits_{i=1}^m \alpha^i y^i x^i \\
\\
&\frac{\partial \mathcal{L}}{\partial b} = 0 \Rightarrow \sum\limits_{i=1}^m \alpha^iy^i = 0
\end{aligned}
$$

将上式代回目标$$ \mathcal{L}(w,b,a) $$，得到：

$$
\mathcal{L}(w,b,\alpha) = \sum\limits_{i=1}^m \alpha^i - \frac{1}{2}\sum\limits_{i=1}^m\sum\limits_{j=1}^m \alpha^i\alpha^jy^iy^j \left \langle x^i,x^j \right \rangle
$$

最终对偶的最优化问题为：

$$
\begin{aligned}
&\max_{\alpha} \sum\limits_{i=1}^m \alpha^i - \frac{1}{2}\sum\limits_{i=1}^m\sum\limits_{j=1}^m \alpha^i\alpha^jy^iy^j \left \langle x^i,x^j \right \rangle \\
&s.t., \alpha^i \ge 0, i = 1, \dots, m \\
&\sum\limits_{i=1}^m \alpha^iy^i = 0
\end{aligned}
$$

# **SVM Kernel**

对于非线性可分数据，最优线性分类器无法找到一个线性的超平面对数据进行分类。一个想法就是，如果我们能找到一个映射$$ \phi $$，将低维空间映射到高维空间，在新的空间中，原数据变得线性可分。

映射过后的对偶问题：

$$
\begin{aligned}
&\max_{\alpha} \sum\limits_{i=1}^m \alpha^i - \frac{1}{2}\sum\limits_{i=1}^m\sum\limits_{j=1}^m \alpha^i\alpha^jy^iy^j \left \langle \phi(x^i),\phi(x^j) \right \rangle \\
&s.t., \alpha^i \ge 0, i = 1, \dots, m \\
&\sum\limits_{i=1}^m \alpha^iy^i = 0
\end{aligned}
$$

最终分类函数：

$$
f(x) = \sum\limits_{i=1}^m \alpha^iy^i \left \langle \phi(x^i),\phi(x^j) \right \rangle + b
$$

映射后的内积计算是非常困难的，例如一个二维$$ X,Y $$平面空间可能映射成五维空间$$ X, X^2, Y, Y^2, XY $$。然而通过定义核函数（Kernel Function)，比如$$ \mathcal{K}(x_1, x_2) = (\left \langle x_1, x_2 \right \rangle + 1)^2 $$，可以通过计算低维空间的内积间接得到高维空间内积结果。

最理想的情况下，我们知道数据的具体分布，得到一个刚好可以将数据映射成线性可分的$$ \phi $$，然后得出对应的内积核函数$$ \mathcal{K} $$。然而不管是对任意的训练数据找到合适的映射，还是通过映射得到合适的核函数，都是非常困难的。实际应用里，通常会从一些常用的核函数中选择，并根据问题和数据的不同，选择不同的参数：
- 多项式核$$ \mathcal{K}(x_1, x_2) = (\left \langle x_1, x_2 \right \rangle + R)^d $$
- 高斯核$$ \mathcal{K}(x_1, x_2) = exp \left ( -\frac{\| x_1 - x_2 \|^2}{2\sigma^2} \right ) $$，高斯核将原始空间映射为无穷维空间。
- 线性核$$ \mathcal{K}(x_1, x_2) = \left \langle x_1, x_2 \right \rangle $$

# **Spark ML 2.3.1**

Spark ML中SVM似乎并没有使用上面通过对偶推导出来的公式，而是直接以最小化经验风险函数为目标（Hinge损失函数）。训练入口调用SVMWithSGD的run方法。
```scala
/**
 * Top-level methods for calling SVM.
 *
 * @note Labels used in SVM should be {0, 1}.
 */
@Since("0.8.0")
object SVMWithSGD {
  /**
   * Train a SVM model given an RDD of (label, features) pairs. We run a fixed number
   * of iterations of gradient descent using the specified step size. Each iteration uses
   * `miniBatchFraction` fraction of the data to calculate the gradient.
   *
   * @note Labels used in SVM should be {0, 1}
   *
   * @param input RDD of (label, array of features) pairs.
   * @param numIterations Number of iterations of gradient descent to run.
   * @param stepSize Step size to be used for each iteration of gradient descent.
   * @param regParam Regularization parameter.
   * @param miniBatchFraction Fraction of data to be used per iteration.
   */
  @Since("0.8.0")
  def train(
      input: RDD[LabeledPoint],
      numIterations: Int,
      stepSize: Double,
      regParam: Double,
      miniBatchFraction: Double): SVMModel = {
    new SVMWithSGD(stepSize, numIterations, regParam, miniBatchFraction).run(input)
  }

  ......
}

/**
 * Train a Support Vector Machine (SVM) using Stochastic Gradient Descent. By default L2
 * regularization is used, which can be changed via `SVMWithSGD.optimizer`.
 *
 * @note Labels used in SVM should be {0, 1}.
 */
@Since("0.8.0")
class SVMWithSGD private (
    private var stepSize: Double,
    private var numIterations: Int,
    private var regParam: Double,
    private var miniBatchFraction: Double)
  extends GeneralizedLinearAlgorithm[SVMModel] with Serializable {

  private val gradient = new HingeGradient()
  private val updater = new SquaredL2Updater()
  @Since("0.8.0")
  override val optimizer = new GradientDescent(gradient, updater)
    .setStepSize(stepSize)
    .setNumIterations(numIterations)
    .setRegParam(regParam)
    .setMiniBatchFraction(miniBatchFraction)
  
  .....
}
```

SVMWithSGD分别初始化gradient和updater为HingeGradient和SquaredL2Updater；optimizer是一个GradientDecent(gradient, updater)。之前[梯度下降](/szyblogs/machine/learning/2018/07/25/gradient-descent/)提到过标准Hinge损失函数定义$$ L(y) = \max (0, 1 - t \centerdot y) $$中t的取值是-1或者1，而label标签取值是0或者1，因此通过`2 * label - 1.0`做了一个映射。SquaredL2Updater也可以参照Ridge回归修正后的梯度下降公式。
```scala
/**
 * :: DeveloperApi ::
 * Compute gradient and loss for a Hinge loss function, as used in SVM binary classification.
 * See also the documentation for the precise formulation.
 *
 * @note This assumes that the labels are {0,1}
 */
@DeveloperApi
class HingeGradient extends Gradient {
  override def compute(
      data: Vector,
      label: Double,
      weights: Vector,
      cumGradient: Vector): Double = {
    val dotProduct = dot(data, weights)
    // Our loss function with {0, 1} labels is max(0, 1 - (2y - 1) (f_w(x)))
    // Therefore the gradient is -(2y - 1)*x
    val labelScaled = 2 * label - 1.0
    if (1.0 > labelScaled * dotProduct) {
      axpy(-labelScaled, data, cumGradient)
      1.0 - labelScaled * dotProduct
    } else {
      0.0
    }
  }
}

/**
 * :: DeveloperApi ::
 * Updater for L2 regularized problems.
 *          R(w) = 1/2 ||w||^2
 * Uses a step-size decreasing with the square root of the number of iterations.
 */
@DeveloperApi
class SquaredL2Updater extends Updater {
  override def compute(
      weightsOld: Vector,
      gradient: Vector,
      stepSize: Double,
      iter: Int,
      regParam: Double): (Vector, Double) = {
    // add up both updates from the gradient of the loss (= step) as well as
    // the gradient of the regularizer (= regParam * weightsOld)
    // w' = w - thisIterStepSize * (gradient + regParam * w)
    // w' = (1 - thisIterStepSize * regParam) * w - thisIterStepSize * gradient
    val thisIterStepSize = stepSize / math.sqrt(iter)
    val brzWeights: BV[Double] = weightsOld.asBreeze.toDenseVector
    brzWeights :*= (1.0 - thisIterStepSize * regParam)
    brzAxpy(-thisIterStepSize, gradient.asBreeze, brzWeights)
    val norm = brzNorm(brzWeights, 2.0)

    (Vectors.fromBreeze(brzWeights), 0.5 * regParam * norm * norm)
  }
}
```

GeneralizedLinearAlgorithm是一个通用的线性模型算法，SVMWithSGD会调用其run方法，其中最核心的一句就是调用optimizer.optimize。Spark ML中的SVM没有实现高斯核，所以无法非线性分类（有种很挫的感觉）。
```scala
/**
 * :: DeveloperApi ::
 * GeneralizedLinearAlgorithm implements methods to train a Generalized Linear Model (GLM).
 * This class should be extended with an Optimizer to create a new GLM.
 *
 */
@Since("0.8.0")
@DeveloperApi
abstract class GeneralizedLinearAlgorithm[M <: GeneralizedLinearModel]
  extends Logging with Serializable {

/**
   * Run the algorithm with the configured parameters on an input RDD
   * of LabeledPoint entries starting from the initial weights provided.
   *
   */
  @Since("1.0.0")
  def run(input: RDD[LabeledPoint], initialWeights: Vector): M = {

    if (numFeatures < 0) {
      numFeatures = input.map(_.features.size).first()
    }

    if (input.getStorageLevel == StorageLevel.NONE) {
      logWarning("The input data is not directly cached, which may hurt performance if its"
        + " parent RDDs are also uncached.")
    }

    // Check the data properties before running the optimizer
    if (validateData && !validators.forall(func => func(input))) {
      throw new SparkException("Input validation failed.")
    }

    /**
     * Scaling columns to unit variance as a heuristic to reduce the condition number:
     *
     * During the optimization process, the convergence (rate) depends on the condition number of
     * the training dataset. Scaling the variables often reduces this condition number
     * heuristically, thus improving the convergence rate. Without reducing the condition number,
     * some training datasets mixing the columns with different scales may not be able to converge.
     *
     * GLMNET and LIBSVM packages perform the scaling to reduce the condition number, and return
     * the weights in the original scale.
     * See page 9 in http://cran.r-project.org/web/packages/glmnet/glmnet.pdf
     *
     * Here, if useFeatureScaling is enabled, we will standardize the training features by dividing
     * the variance of each column (without subtracting the mean), and train the model in the
     * scaled space. Then we transform the coefficients from the scaled space to the original scale
     * as GLMNET and LIBSVM do.
     *
     * Currently, it's only enabled in LogisticRegressionWithLBFGS
     */
    val scaler = if (useFeatureScaling) {
      new StandardScaler(withStd = true, withMean = false).fit(input.map(_.features))
    } else {
      null
    }

    // Prepend an extra variable consisting of all 1.0's for the intercept.
    // TODO: Apply feature scaling to the weight vector instead of input data.
    val data =
      if (addIntercept) {
        if (useFeatureScaling) {
          input.map(lp => (lp.label, appendBias(scaler.transform(lp.features)))).cache()
        } else {
          input.map(lp => (lp.label, appendBias(lp.features))).cache()
        }
      } else {
        if (useFeatureScaling) {
          input.map(lp => (lp.label, scaler.transform(lp.features))).cache()
        } else {
          input.map(lp => (lp.label, lp.features))
        }
      }

    /**
     * TODO: For better convergence, in logistic regression, the intercepts should be computed
     * from the prior probability distribution of the outcomes; for linear regression,
     * the intercept should be set as the average of response.
     */
    val initialWeightsWithIntercept = if (addIntercept && numOfLinearPredictor == 1) {
      appendBias(initialWeights)
    } else {
      /** If `numOfLinearPredictor > 1`, initialWeights already contains intercepts. */
      initialWeights
    }

    val weightsWithIntercept = optimizer.optimize(data, initialWeightsWithIntercept)

    val intercept = if (addIntercept && numOfLinearPredictor == 1) {
      weightsWithIntercept(weightsWithIntercept.size - 1)
    } else {
      0.0
    }

    var weights = if (addIntercept && numOfLinearPredictor == 1) {
      Vectors.dense(weightsWithIntercept.toArray.slice(0, weightsWithIntercept.size - 1))
    } else {
      weightsWithIntercept
    }

    /**
     * The weights and intercept are trained in the scaled space; we're converting them back to
     * the original scale.
     *
     * Math shows that if we only perform standardization without subtracting means, the intercept
     * will not be changed. w_i = w_i' / v_i where w_i' is the coefficient in the scaled space, w_i
     * is the coefficient in the original space, and v_i is the variance of the column i.
     */
    if (useFeatureScaling) {
      if (numOfLinearPredictor == 1) {
        weights = scaler.transform(weights)
      } else {
        /**
         * For `numOfLinearPredictor > 1`, we have to transform the weights back to the original
         * scale for each set of linear predictor. Note that the intercepts have to be explicitly
         * excluded when `addIntercept == true` since the intercepts are part of weights now.
         */
        var i = 0
        val n = weights.size / numOfLinearPredictor
        val weightsArray = weights.toArray
        while (i < numOfLinearPredictor) {
          val start = i * n
          val end = (i + 1) * n - { if (addIntercept) 1 else 0 }

          val partialWeightsArray = scaler.transform(
            Vectors.dense(weightsArray.slice(start, end))).toArray

          System.arraycopy(partialWeightsArray, 0, weightsArray, start, partialWeightsArray.length)
          i += 1
        }
        weights = Vectors.dense(weightsArray)
      }
    }

    // Warn at the end of the run as well, for increased visibility.
    if (input.getStorageLevel == StorageLevel.NONE) {
      logWarning("The input data was not directly cached, which may hurt performance if its"
        + " parent RDDs are also uncached.")
    }

    // Unpersist cached data
    if (data.getStorageLevel != StorageLevel.NONE) {
      data.unpersist(false)
    }

    createModel(weights, intercept)
  }
}
```

参考：  
[知乎：支持向量机(SVM)算法原理](https://zhuanlan.zhihu.com/p/28660098)  
[支持向量机系列](http://blog.pluskid.org/?page_id=683)  
[SVM基础](http://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/basic-of-svm.html)